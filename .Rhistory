df
}
purpose <- bandung_data |> filter(topic=="purpose")
View(purpose)
purpose_df <- create_df(purpose)
View(purpose_df)
df_test <- df |> left_join(purpose, by = "word")
?left_join
df_test <- df |> left_join(purpose_df, by = "word")
View(df_test)
df_test <- df |> left_join(purpose_df, by = "word", suffix = c(".all, .purpose"))
View(df_test)
df_test <- df |> left_join(purpose_df, by = "word", suffix = c(".all", ".purpose"))
write.csv(df_test, "df_test.csv")
bandung_data <- read.csv("bandung_data.csv", na.strings="")
bandung_data$text <- str_to_lower(bandung_data$text)
general <- bandung_data |> filter(topic=="general")
general_df <- create_df(general)
df_test <- df |> left_join(general_df, by = "word", suffix = c(".all", ".general"))
write.csv(df_test, "df_test.csv")
View(df_test)
write.csv(df_test, "df_test.csv")
write.csv(df_test, "df_general.csv")
View(purpose_df)
write.csv(df_test, "df_purpose.csv")
View(df_test)
df_test <- df |> left_join(purpose_df, by = "word", suffix = c(".all", ".purpose"))
View(purpose_df)
df_test <- df |> left_join(purpose_df, by = "word", suffix = c(".all", ".purpose"))
View(df_test)
write.csv(df_test, "df_purpose.csv")
write.csv(df_test, "df_test.csv")
bandung_data <- read.csv("bandung_data.csv", na.strings="")
bandung_data$text <- str_to_lower(bandung_data$text)
general <- bandung_data |> filter(topic=="general")
purpose <- bandung_data |> filter(topic=="purpose")
bandung_data$topic |> unique()
communique <- bandung_data |> filter(topic=="communique")
press <- bandung_data |> filter(topic=="press")
library(tm)
address <- bandung_data |> filter(topic=="address")
general_df <- create_df(general)
purpose_df <- create_df(purpose)
general_df <- create_df(general)
communique_df <- create_df(communique)
press_df <- create_df(press)
address_df <- create_df(address)
View(df_test)
df_test <- df_test |> left_join(general_df, by = "word")
View(df_test)
df_test <- df |> left_join(purpose_df, by = "word", suffix = c(".all", ".purpose"))
df_test <- df_test |> left_join(general_df, by = "word", suffix = c(".test", ".general"))
View(df_test)
View(df_test)
df_test |> rename(freq.general = freq)
df_test <- df_test |> rename(freq.general = freq)
write.csv(df_test, "df_test2.csv")
purpose_df <- create_df(purpose)
general_df <- create_df(general)
communique_df <- create_df(communique)
press_df <- create_df(press)
address_df <- create_df(address)
?left_join
df_test <- df_test |> left_join(communique_df, by = "word")
df_test <- df_test |> rename(freq.communique = freq)
View(df_test)
df_test <- df_test |> left_join(press_df, by = "press")
df_test <- df_test |> rename(freq.press = freq)
df_test <- df_test |> left_join(press_df, by = "word")
df_test <- df_test |> rename(freq.press = freq)
write.csv(df_test, "df_test2.csv")
library(shiny)
library(shinythemes)
library(tidyverse)
library(wordcloud2)
library(tm)
source("ui.R")
source("server.R")
bandung_data <- read.csv("data/bandung_data.csv", na.strings="")
?sidebarLayout
runApp()
runApp()
runApp()
runApp()
?wordcloud2
runApp()
?a
runApp()
?icon
runApp()
?img
runApp()
ui <- fluidPage(
tags$head(tags$style(
HTML("
@import url('https://fonts.googleapis.com/css2?family=Inter&display=swap');
.tab-content {margin:50px 100px;}
h1, h4 {font-family: 'Inter', sans-serif;}
body {font-family: 'Inter', sans-serif; margin: 40px 0px; padding: 10px 0px;}
"))),
theme = shinytheme("slate"),
h1("1955 Bandung Asian-African Conference Bulletins",
align="center",),
h4("A Visual Summary" |> str_to_upper(), align="center",
style="color:#A3A3A3;margin-bottom:25px;"),
tabsetPanel(
# br(),
# Word cloud tab
tabPanel(
title = "Word Cloud",
sidebarLayout(
sidebarPanel(
h4("Content Filters"),
br(),
selectInput(
inputId = "topic",
label = strong("Bulletin content topic"),
choices = c("All", unique(bandung_data$topic)),
),
# Select dual nationality subtopic
checkboxInput(
inputId = "dualNationality",
label = strong("Show only China-Indonesia dual nationality related content")
),
checkboxInput("removeWords", strong("Remove specific words?"), FALSE),
conditionalPanel(
condition = "input.removeWords == 1",
textAreaInput("wordsToRemove", "Words to remove (separated by comma)", rows = 1)
),
# Display select press region only if press is checked
conditionalPanel(
condition = "input.topic.indexOf('press') > -1",
checkboxGroupInput(
inputId = "pressRegion",
label = "Press region",
choices = c("Asia and Africa", "Australia", "Europe", "America")
)),
# Select Delegates
selectInput(
inputId = "delegateHead",
label = "Delegate head",
choices = c("All", unique(bandung_data$delegate)[2:35])
),
conditionalPanel(
condition = "input.topic.indexOf('address') > -1",
checkboxGroupInput(
inputId = "addressType",
label = "Opening or closing address",
choices = c("Opening", "Closing")
)),
br(),
br(),
p("View the dataset and code on the ", a(href="https://github.com/yauyenching/bandung-bulletins", "GitHub repo."))
),
mainPanel(wordcloud2Output("wordcloud", width = "100%"))
)
),
# About Bandung Conference panel
tabPanel(
title = "About the Bandung Conference",
fluidRow(
column(4, img(src="https://images.news18.com/ibnlive/uploads/2017/08/Bandung-Conference.jpg?impolicy=website&width=510&height=356",
style="display:block;margin-left:auto;margin-right:auto;width:100%")),
column(
8,
h4(strong("What is the Bandung Conference?"), align="center"),
br(),
p("
In April, 1955,
delegates from 29 Asian and African countries and regions
gathered in Bandung, Indonesia to discuss navigating a postcolonial world
and calling for greater solidarity, mutual respect, non-aggression, and equality.
This event marked an emerging community of developing nations, many of which were
newly independent from colonial powers.
Today, the Asian-African Conference is recognized as an example of one of the
largest cooperative efforts between Third World countries to articulate a shared vision
in the face of great monopolizing world powers."),
h4(strong("What is this Project?"), align="center"),
br(),
p("
This project aims to provide an accessible visual summary over the conference
bulletin contents which were made publicly available by the Indonesian ministry
of information. PDFs of the bulletins can be accessed ",
a(href="https://bandung60.wordpress.com/bandung-bulletin/", "here.")
)
)
)
?tabsetPanel
?fluidRow
runApp()
install.packages('rsconnect')
rsconnect::setAccountInfo(name='yauyenching', token='F6F343E1DB12E42509DA4088D3ED58C0', secret='cuENmhRuONfRstRQoBiFGE9iavwV111sGi3tuYLP')
library(rsconnect)
rsconnect::deployApp('app')
rsconnect::deployApp('app.R')
rsconnect::deployApp('.')
runApp()
rsconnect::deployApp('.')
runApp()
bandung_data <- read.csv("data/bandung_data.csv", na.strings="")
bandung_data <- read.csv("data/bandung_data.csv", na.strings="")
runApp()
runApp()
runApp()
runApp()
runApp()
library(shinythemes)
runApp()
rsconnect::deployApp('.')
runApp()
rsconnect::deployApp('.')
runApp()
runApp()
?str_to_upper
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
rsconnect::deployApp('.')
rsconnect::deployApp('.')
library(tidyverse)
library(wordcloud2)
library(tm)
bandung_data <- read.csv("data/bandung_data.csv", na.strings="")
text <- bandung_data$text
text <- iconv(text, to = "UTF-8")
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
words_to_remove <-
if (input$removeWords) {
str_split(input$wordsToRemove, ",")[[1]]
} else {
NA
}
docs <- tm_map(docs, removeWords, c("conference", words_to_remove, stopwords("english")))
dtm <- as.matrix(TermDocumentMatrix(docs))
text <- bandung_data$text
text <- iconv(text, to = "UTF-8")
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
words_to_remove <-
if (input$removeWords) {
str_split(input$wordsToRemove, ",")[[1]]
} else {
NA
}
docs <- tm_map(docs, removeWords, c("conference", stopwords("english")))
dtm <- as.matrix(TermDocumentMatrix(docs))
dtm.subset <-  removeSparseTerms(dtm, 0.4)
dtm.subset
dtm <- TermDocumentMatrix(docs)
dtm.subset <-  removeSparseTerms(dtm, 0.4)
View(dtm.subset)
kmeans.data <- as.matrix(t(dtm.subset))
kfit <- kmeans(kmeans.data, 2)
kfit
kfit |> plot()
kfit
View(dtm.subset)
dtm <- TermDocumentMatrix(docs)
dtm.subset <-  removeSparseTerms(dtm, 0.2)
kmeans.data <- as.matrix(t(dtm.subset))
kfit <- kmeans(kmeans.data, 2)
kfit
dtm.subset <-  removeSparseTerms(dtm, 0.6)
kmeans.data <- as.matrix(t(dtm.subset))
kfit <- kmeans(kmeans.data, 2)
kfit
kfit <- kmeans(kmeans.data, 3)
kmeans(kmeans.data, 3)
k <- 7
varper <- NULL
for (i in 1:k) {
kfit <- kmeans(kmeans.data, i)
varper <- c(varper, kfit$betweenss/kfit$totss)
}
plot(1:k, varper, xlab = "# of clusters", ylab = "explained variance")
k <- 10
varper <- NULL
for (i in 1:k) {
kfit <- kmeans(kmeans.data, i)
varper <- c(varper, kfit$betweenss/kfit$totss)
}
plot(1:k, varper, xlab = "# of clusters", ylab = "explained variance")
k <- 20
varper <- NULL
for (i in 1:k) {
kfit <- kmeans(kmeans.data, i)
varper <- c(varper, kfit$betweenss/kfit$totss)
}
plot(1:k, varper, xlab = "# of clusters", ylab = "explained variance")
dtm <- TermDocumentMatrix(docs)
kmeans.data <- as.matrix(t(dtm.subset))
kmeans(kmeans.data, 3)
k <- 20
varper <- NULL
for (i in 1:k) {
kfit <- kmeans(kmeans.data, i)
varper <- c(varper, kfit$betweenss/kfit$totss)
}
kmeans.data <- as.matrix(t(dtm))
k <- 20
varper <- NULL
for (i in 1:k) {
kfit <- kmeans(kmeans.data, i)
varper <- c(varper, kfit$betweenss/kfit$totss)
}
plot(1:k, varper, xlab = "# of clusters", ylab = "explained variance")
dtm.subset <-  removeSparseTerms(dtm, 0.6)
kmeans.data <- as.matrix(t(dtm.subset))
k <- 20
varper <- NULL
for (i in 1:k) {
kfit <- kmeans(kmeans.data, i)
varper <- c(varper, kfit$betweenss/kfit$totss)
}
plot(1:k, varper, xlab = "# of clusters", ylab = "explained variance")
dtm <- TermDocumentMatrix(docs)
dtm.subset <-  removeSparseTerms(dtm, 0.6)
kmeans.data <- as.matrix(t(dtm.subset))
k <- 20
varper <- NULL
for (i in 1:k) {
kfit <- kmeans(kmeans.data, i)
varper <- c(varper, kfit$betweenss/kfit$totss)
}
plot(1:k, varper, xlab = "# of clusters", ylab = "explained variance")
kmeans(kmeans.data, 7)
dtm <- TermDocumentMatrix(docs)
dtm.subset <-  removeSparseTerms(dtm, 0.5)
kmeans.data <- as.matrix(t(dtm.subset))
k <- 20
varper <- NULL
for (i in 1:k) {
kfit <- kmeans(kmeans.data, i)
varper <- c(varper, kfit$betweenss/kfit$totss)
}
plot(1:k, varper, xlab = "# of clusters", ylab = "explained variance")
dtm <- TermDocumentMatrix(docs)
dtm.subset <-  removeSparseTerms(dtm, 0.5)
kmeans.data <- as.matrix(t(dtm.subset))
set.seed(42)
k <- 20
varper <- NULL
for (i in 1:k) {
kfit <- kmeans(kmeans.data, i)
varper <- c(varper, kfit$betweenss/kfit$totss)
}
plot(1:k, varper, xlab = "# of clusters", ylab = "explained variance")
kmeans(kmeans.data, 6)
kfit <- kmeans(kmeans.data, 6)
kfit$cluster
text <- bandung_data$text
prof.tm <- unnest_tokens(text, word, comments)
install.packages("tidytext")
library(tidytext)
text <- bandung_data$text
?unnest_tokens
d <- tibble(txt = prideprejudice)
library(janeaustenr)
d <- tibble(txt = prideprejudice)
View(d)
prof.tm <- unnest_tokens(text)
d <- tibble(txt = text)
View(d)
prof.tm <- unnest_tokens(word, txt)
prof.tm <- unnest_tokens(d, word, txt)
View(prof.tm)
stopwords <- read_csv("data/stopwords.evaluation.csv")
prof.tm <- prof.tm %>% stopwords("english")
prof.tm <- prof.tm %>% anti_join(stopwords("english"))
prof.tm <- prof.tm %>% anti_join(stopwords("english"))
text <- bandung_data$text
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, c("conference", stopwords("english")))
dtm <- as.matrix(TermDocumentMatrix(docs))
df <- data.frame(word = names(words),freq=as.numeric(words))
dtm <- as.matrix(TermDocumentMatrix(docs))
df <- data.frame(word = names(words),freq=as.numeric(words))
words <- as.matrix(TermDocumentMatrix(docs))
df <- data.frame(word = names(words),freq=as.numeric(words))
words <- sort(rowSums(dtm),decreasing=TRUE)
dtm <- as.matrix(TermDocumentMatrix(docs))
words <- sort(rowSums(dtm),decreasing=TRUE)
df <- data.frame(word = names(words),freq=as.numeric(words))
df
View(df)
df.dtm <- df |> cast_dtm(profid, word, n)
?cast_dtm
View(df)
df.dtm <- df |> cast_dtm(word, n)
df.dtm <- df |> cast_dtm(word, freq)
dtm <- docs %>% count(word) %>% cast_dtm(word, n)
dtm <- as.matrix(TermDocumentMatrix(docs))
dtm <- TermDocumentMatrix(docs)
dtm.subset <-  removeSparseTerms(dtm, 0.5)
kmeans.data <- as.matrix(t(dtm.subset))
kfit <- kmeans(kmeans.data, 6)
kfit$cluster
kmeans.data
View(kmeans.data)
dtm <- TermDocumentMatrix(docs)
dtm.subset <-  removeSparseTerms(dtm, 0.6)
kmeans.data <- as.matrix(t(dtm.subset))
set.seed(42)
k <- 20
varper <- NULL
for (i in 1:k) {
kfit <- kmeans(kmeans.data, i)
varper <- c(varper, kfit$betweenss/kfit$totss)
}
plot(1:k, varper, xlab = "# of clusters", ylab = "explained variance")
kfit <- kmeans(kmeans.data, 7)
kfit$cluster
tm::inspect(dtm.subsetr)
tm::inspect(dtm.subset)
kmeans.data <- as.matrix(dtm.subset)
tm::inspect(dtm.subset)
set.seed(42)
k <- 20
varper <- NULL
for (i in 1:k) {
kfit <- kmeans(kmeans.data, i)
varper <- c(varper, kfit$betweenss/kfit$totss)
}
plot(1:k, varper, xlab = "# of clusters", ylab = "explained variance")
kfit <- kmeans(kmeans.data, 7)
kfit$cluster
kfit
kfit$cluster
kfit$cluster |> plot()
kfit$cluster
kfit$cluster |> sort()
shiny::runApp()
runApp()
rsconnect::deployApp(.)
rsconnect::deployApp(".")
runApp()
rsconnect::deployApp(".")
bandung_data <- read.csv("data/bandung_data.csv", na.strings="")
unique(bandung_data$delegate)[2:35] |> sort()
runApp()
View(bandung_data)
runApp()
create_wordcloud <- function(word_data) {
text <- word_data$text
text <- iconv(text, to = "UTF-8")
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
words_to_remove <-
if (input$removeWords) {
str_split(input$wordsToRemove, ",")[[1]]
} else {
NA
}
docs <- tm_map(docs, removeWords, c("conference", words_to_remove, stopwords("english")))
dtm <- as.matrix(TermDocumentMatrix(docs))
words <- sort(rowSums(dtm),decreasing=TRUE)
df <- data.frame(word = names(words),freq=as.numeric(words))
row.names(df) <- NULL
df
}
create_wordcloud(bandung_data |> filter(address_type == "Opening"))
test <- create_wordcloud(bandung_data |> filter(address_type == "Opening"))
docs <- tm_map(docs, removeWords, c("conference", stopwords("english")))
create_wordcloud <- function(word_data) {
text <- word_data$text
text <- iconv(text, to = "UTF-8")
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, c("conference", stopwords("english")))
dtm <- as.matrix(TermDocumentMatrix(docs))
words <- sort(rowSums(dtm),decreasing=TRUE)
df <- data.frame(word = names(words),freq=as.numeric(words))
row.names(df) <- NULL
df
}
test <- create_wordcloud(bandung_data |> filter(address_type == "Opening"))
View(test)
test[test$word == "indonesia",]
rsconnect::deployApp(.)
rsconnect::deployApp(".")
closing <- create_wordcloud(bandung_data |> filter(address_type == "Closing"))
closing[closing$word == "economic",]
opening <- test
opening[opening$word == "economic",]
opening[opening$word == "common",]
